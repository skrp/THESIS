4####################################################
# MKRX UNIX NETWORK

                                             ~ skrp
                                       Kehkay Genkai
                                      of the village
                                  Hidden in the 1337
{{  t_(o0)_j  }}
\\ Meri Kann //
_\\cibR punX//______________________________________
|
|
|
|
|
|
|
This manuscript details the machine of MKRX UNIX NETWORKS
This system connects nodes thru encrypted tunnels

SICC network file system
MKRX archive tools
HIVE work processors

KERN hardened FreeBSD_10.3 custom unix kernels
PSK-OPIE privilege partition & escalation

PROTO unix network protocol implementations
STAT node & network dtrace sensor analysis

ZFS diagrams PCI, SATA, SAS, USB
Schematics & Utilities

MAN manuals of instructions & examples

Network Value is contained in 4 sectors
  {#} Storage shares - nfs
  {#} Process clones - HIVE
  {#} Cryptographic Security - PSKOPIE elliptic-curves
  {#} Services - ssh

|
|
|
|
|
|
|
Let us preserve all insight
Till the last man walk

That he might not walk
In the darkness of past

Independent of time
Independent of wealth
Independent of government

In the order of Anarchy
In that way deliver basic rights

Files get lost
Storage gets easier
|
|
|
|
|
|
|
####################################################
# Table of Contents
####################################################

# 0 ################################################
SICC
  Standard
  Metadata
  Key
  shaper
  BLKR

# 1 ################################################
MKRX
  Tools explained
  Tool use & examples
    create GET from BKUP
    create GET from UNIQ
    populate a new drive
    extract a source

# 2 ################################################
HIVE
  Structure
  Mechanics
    ORDER
    SLEEP
    SUICIDE
    CLEAN
    RESUME
  API
    SHA
    GET
    UNTAR
    REGX
    BLKR
  Logs

# 3 ################################################
KERN
  Hardened
  PSK-OPIE
  RINGS (rings of power)
  USR
    root
    sroot
    lord
    heir
    seer
    norm

# 4 ################################################
PSK-OPIE
  Review
  ASIGN
  Mine
    KEY
    RAW

# 5 ################################################
PROTO
  Overview
  SSH
  SCP
  FTP
  PF
  NFS
  IRC
  8080
  HTTPS
  MORSE

# 6 ################################################
STAT
  List
  dtrace
    cpu
    PID
    fs
    net
  Performance
    LOG
    ECHO
  ANAL
    SELF
    NET

# 7 ################################################
ZFS & Hardware
  ZFS
    0
    Mirror
    raidz2
    raidz3
  Hardware
    BOX
    BIOS
    cpu
    RAM
    PCI
    DEV
    Supply
    PCI
    SATA
    SAS
    USB
    JBOD

# 8 ################################################
SCHMATIC
  SIMP
  TOWR
  Utilities

# 9 ################################################
MAN
  unix manuals
    log
    mount
    boot
    ntfs
  perl manuals
    log
    language
    modules
  zfs manuals
    log
    hotswap
    import
    set
  dtrace manuals
    language

# END ##############################################
|
|
|
|
|
|
|
####################################################
# 0 - SICC
####################################################

######## System In Complete Chaos    ###############

Storage shares are the most important factor in this network
Archive-oriented structures are implemented as a network-wide pursuit of unique files

/usr/nfs/dump/ 330 write-only dump-dir which will be scraped into the SICC-system at /usr/nfs/pub/
(this exposes the pub to the network for file exchange)
SICC will process all files into a sane manner built to handle massive numbers

Storage has a next important factor is entropy strength
Entropy is stored to be traded with other hosts

Entropy over-time multiple-source random-selection
Each Private-Key stored as its sha

To sum up
Data is kept as a sea such that the listing freeze a system

Obfuscation by explicit filename requests
Random-parts of random-files in hexadecimal order with no association

To piece together the file
  [:D] - Metadata file
  [:D] - KEY file
  [:D] - shape pool
  [:D] - KEY$ payment

# NAME SYSTEM ######################################

The core of this system is based on sha file computation

Sha is a unique file identifier that is the output of a mathematical algorithm
This mathematical algorithm will produce the same sha for the same file

Each file is named after its sha

This name system has two benefits:
  {1} de-duplicates files
  {2} assigns data into chaotic order

Sha uniqueness keeps all data:
  [-] simple
  [-] homogeneous
  [-] ultra-transient

The duplication of data is accounted in lists
Each data-pool is maximized in its ability to minimize the data-pool's disk-footprint

The duplication count allows for network backup prioritization to remote devices
This foundation is stable for automated backup management of massive-distributed-data

# METADATA #######################################

Metadata is kept isolated from data
This isolation allows for the obfuscation of open data

Data-pool lists have lessened-value without Metadata
Exposure of lists can be nullified by salt

Only someone that has the metadata & access-key can request data

This file-system is built for ultra-transient network management
All files are located in the directory "/usr/nfs/pub/"

Two factors assist in obfuscation
  (1) No subdirectories to betray association
  (2) Alpha-numeric ordering of the hexadecimal names

The path allows for past-association to be deduced for group-reconstruction
Each file is periodically verified to have a corresponding metadata-file

Each metadata-file consists of 4 lines:
  (1) name - XS (MKRX) standardized name
  (2) path - XS standardized path of extraction
  (3) size - number of bytes
  (4) encode - type of encoding

# KEY ##############################################

A KEY is a recipe to rebuild an obfuscated file

This allows for a powerful layer of unprecedented obfuscation
What is public gibberish is made private information thru access to a KEY file

Each KEY file is named after the original file sha
The KEY file contains sequential sha-per-line lists

Obfuscation Methods:

  [X] shaper (secure against file-known)
        Shreds a file into random-sized parts & creates KEY
        Random-size prevents sha rainbow-tables of attacker with file-known

  [X] BLKR (insecure if file-known)
       Shreds file into standard-sized blocks & creates KEY
       Homogeneous data types will have duplicate-collisions which nullify the duplicate data
       Only one copy of data can exist in the data-pool
       Many KEY files can correspond to the same block reducing the data-pool disk-footprint
       The smaller block-size the greater power of compression & obfuscation of data-pool
       Each node configures own block-size

# SUMMARY #########################################

This file-system spread over a network has the following benefits:
  [o] All data easily accounted for in simple lists
  [o] Sane & clean orders of massive-data on an network
  [o] Network level explicit control of the duplication of data
  [o] Each node serves what is possible
  [o] Each node has access to total data
  [o] Each node can assist in external backups
  [o] Total network-pool footprint is minimized

On a homogeneous unix kernel the network file-system is transparent
Only active tunnels will be displayed as available data-pools

Transparent file-system
  [l] store data remotely
  [l] get a remote file
  [l] serve a local file
  [l] backup network to local drive
|
|
|
|
|
|
|
####################################################
# 1 - MKRX
####################################################
Tools to administer the network file-system

MKRX Tools:
  [XS]
    Extract & Standardize Recursively
  [SCRUB]
    Verify if sha of file is true
  [CHKMETA]
    Confirm each file has metadata
  [UNIQ]
    Output unless (ARG1-files exist in ARG2-files)
  [XFR]
    Serve data to local drive
    Serve data to remote locations
  [INDEX]
    Build Metadata hash-dumps
  [CLI]
    Load INDEX hash-dumps into memory
    Terminal Input & Output produce single-entry lists


# XS ###############################################

Extract & Standardize All Files Recursively
  Send data to pool-dir
  Build metadata in g-dir

This process is the gateway for files to enter the archive
High io usage & multiple process utilization

Features the expert developer kent\n
This code been worked over 100s millions of files

Automatic logic
Just point & pull trigger

Name & path values are standardized to keep environment safe
The path allows for past-association awareness
Size & encoding keep calculations one-time-only

# UNIQ ############################################

Output if ARG1 does-not-exist in ARG2

Filter data that is unique on the network
Compare NODE-list against NET-list
Backup the network with priority files needing duplication

This is a very useful command
It can handle millions of iterations in both ARGs

Learn the simple code mechanic & this command will prove a general system tool
In minutes this processes data that would require many days for grep

# CLI ############################################

Interface to network archive requests custom file requests
This is a daemon server that keeps METAMASTER in memory
Transactions are hexadecimal arrays

  [1] Build INDEX hash-dumps into memory
    This may take several minutes due to massive-data

  [2] Build array-list
    Set to network array-list
    Load a custom array-list from file

  [3] Filter down array list
    Use perl regular-expressions to parse patterns

  [4] Report on array-list
    Print a filtered array to file
    Count the quantity in array-list
    Output the corresponding array-list value
      name, path, size, encode

  [5] Create lists of files bound to a byte-parameter
    The calculation of sums add up when it is to the millions
    Array-list is sectioned into specific-sized chunks

  [6] Use XFR to request the files into home directory
    This process will only require a feed of the output which is the array-list
    Array-list will always only be the sha of filtered file-metadata

  [7] Use conditional regular-expressions to edit the array-list names into a new-file
    After XFR complete use new-file to rename array-list files

Command Menu:
  {regx}  regx data filters
  {reset} reset array to full network-array
  {load}  load array from custom file
  {print} output current array to file
  {count} count array
  {value} output values of array 'name, path, size, encoding'
  {pop}   output size-specific lists that sum to a specific-amount of bytes
  {name}  edit name using conditional regx into new-file

# EXAMPLES #######################################

[1]
Create GET for backup
  {TOTAL_NET}   location of network-wide file list
  {TOTAL_LOCAL} location of local file list
  {GET}         single-entry line lists of what TOTAL_LOCAL lacks from TOTAL_NET
+++++++++++++++++++++++++++++++++++++++++++++++++++
$usr@host> UNIQ TOTAL_NET TOTAL_LOCAL GET
+++++++++++++++++++++++++++++++++++++++++++++++++++

[2]
Create EXTRACT from UNIQ
  {TOTAL_SOURCE} sha lists of a source
  {TOTAL_NET} network-wide file list
  {EXTRACT} new unique files to network list
+++++++++++++++++++++++++++++++++++++++++++++++++++
$usr@host> UNIQ TOTAL_SOURCE TOTAL_NET EXTRACT
+++++++++++++++++++++++++++++++++++++++++++++++++++

[3]
Populate a new drive
  {~/INDEX/}         location of INDEX metadata database hash dumps
  {~/POP/1000000000} file to transfer
  {/mnt/USB/pool/}   location to dump files
+++++++++++++++++++++++++++++++++++++++++++++++++++
$usr@host> CLI ~/INDEX/
pop 1000000000
exit
+++++++++++++++++++++++++++++++++++++++++++++++++++
$usr@host> cd ~/POP/
+++++++++++++++++++++++++++++++++++++++++++++++++++
$usr@host> wc -l 1000000000
8493719 1000000000
+++++++++++++++++++++++++++++++++++++++++++++++++++
$usr@host> wc -l leftover_1000000000
39533365846 leftover_1000000000
+++++++++++++++++++++++++++++++++++++++++++++++++++
$usr@host> XFR ~/POP/1000000000 /mnt/USB/pool/
+++++++++++++++++++++++++++++++++++++++++++++++++++
$usr@host> CLI ~/INDEX/
load leftover_1000000000
pop 1000000000
exit
+++++++++++++++++++++++++++++++++++++++++++++++++++
Loop over & over by gigabyte-sized fragments

[4]
Extract a source
  {/mnt/bkup10/} location to grab new data
  {~/} location to dump data into ~/pool/ & ~/g/
+++++++++++++++++++++++++++++++++++++++++++++++++++
$usr@host> XS /mnt/bkup10/ ~/
+++++++++++++++++++++++++++++++++++++++++++++++++++


# DISK #############################################

Two types of storage
  [r] - root storage
    This is a location that resides upon a root-file-system of a kernel
      /usr/nfs/pub/
  [r] - flat storage
    An external disk that contains only an imported pool of files
      /37w/pool/ or /usr/nfs/37w/pool/

/usr/nfs/pub/  - zfs mount
/usr/nfs/373/  - nfs mount
/usr/nfs/y7u/  - nfs mount

External-drives are necessary for clean access to a file-system
A foreign system can port-itself to mount the simple zfs file-system

The root storage is only slightly more complex
A trade to only then need a amd64 machine architecture to start up


/zroot/boot/ - lord only privilege
---------------------------- DESCRETE LINE
/usr/nfs/pub/ - zfs quota protection
/usr/nfs/el1/ - nfs mount
/usr/nfs/z87/ - nfs mount
|
|
|
|
|
|
|
####################################################
# 2 - HIVE
####################################################

Network TXN (transactions) are based on KEY$ currency
Creating & trading private-keys as a means for network access

Usr sends unstable-input to HIVE
A DEMON stablizes-input & computes
HIVE deposits payment into usr bank
Usr buys host-keys & trades them for specified-host-keys

Each heart of each node singular in the aim of Archive
Data stored for the future & it will offer refuge to any helpful

Encode bounty * group-multiplier = payment
Payment is exchanged for group-limited private-keys

Private-key will be used to open a tunnel
Pre-Shared-Key One-Time-In-Everything
_

Massive projects will be broken down into iterative-tasks
Usr will work DEMON upon sections of those iterative-tasks

Two quest areas
  ["] - harvest of novel workloads lists
  ["] - compute lists

Each project will be distributed to array-computation

project / network-nodes = time
  time + network latency = total-time

Benefits of network-sync-computation
  Randomize Entropy Sources
  Scrape data off from many sources to not cause attention
  Shred data into random-sized blocks
  Clean up host into network dump
  Allow many users to contribute metadata to Archive Collections Interface
  Distribute loads from disk to network to cpu to disk... to empower robustness
  Health-Beat of host via dtrace anchors

A network of DEMON (unix daemon) work on a schedule
  Busy (low all)
    Scrape http data
  Mid (low net)
    Entropy collection
  Bored (high all)
    shaper
    SHA

# NET ##############################################

HIVE
    {T}    get www.pedrk.com/tome.txt
  {     }  blkr $i
{ FACE    }
    ||
    ||
    ||
    ||
    ||                    key_4ff38 < [usr]
    ||                    key_ff9aae   v   > key_d3413
    ||
    ||
    ||
   {T}       sleep 3600                                {T}      sleep 3600
 {     }     get www.nasa.com/sun/index.html         {     }    kripkey
{ FACE  } ========================================{ FACE     }  shaper $i

FACE
This is an ASCII graphical representation of the NODE
STATE represents the HOST each report independent to other DEMON
  [y] NAME
  [Y] STATE
  [y] AGE_IN_HOURS
  [y] SUCCESSFUL_ITERATIONS (YAY, 5-line-success-buffer)


Commands (all or node)
  PING - alive last 15-min
  SLEEP - pause all (may take forever to infinity)
  RAW - all output log
  HICC - fail / error
  BURP - cat log of successful iterations
  FACE - echo DEMON portrait
  REIN - iograph of net & individual data
  BARK - { [PING * ALLOWANCE] < 10%_expected }
  SUICIDE - clean-up then kill-itself

A HIVE cumulative workload should never breach 20% of maximum
The goal behind this work is to allow sanity thru dissociative-scheduled-massive-computation of a network of these HIVE

# NODE #############################################

A unix daemon is an process that severs all-but-explicit interface file descriptors
This provides an independence which stabilizes the foundation of the code
This code is a summon-scroll crafted to deal with specific actions
  The process can be suspended-shutdown-update_que by an admin able to write in a locked-down dir
  The DEMON-INTERFACE will all specific tasks in an explicit command execution

The Achilles heel of distributive computing are fork-bombs & defunct-muthrfkrs
Fork bombs are nasty & bloom out of any inconsistency [like invasive network probes]
Defunct processors are unkillable in certain situations
You can never automate continuously running programs without a sensitivity to host health
There is a reason animals have a nervous system & we must forward those lessons onto the machine race
The sensitivity of the host system will be the stable foundation with catches fork bombs
  Every host will have an avatar maintained by HIVE
  This will be a depiction of the health which will have numerical value
  If any net-process over 50% utilized-cpu then cleanup & exit or sleep

Full-access given to any network node with proper Pre-Shared-Keys Once-In-Everything-Passwords
This allows a network to be delegated remotely to partitioned unix groups
  pig_fkn_redneck wants a torrent downloaded at maximum-strength crypto
  The code will inspect the PSK, shift the key off the array, and have x proxy nodes download the file in pieces
  When the torrent is complete, verified & archived it is placed in /usr/home/pig_fkn_redneck/torrent/Udders_for.udder.lovers.mp4

# FUNCTIONS #########################################

tombstone() name() time()
Each DEMON has a unique name that will be memorialized with its lifeswork
For a member to enrich the whole, first the society must cherish the member
The tombstone is a snapshot of the last DEMON portrait FACE

que_r() que_up() que_flush() api_verify()
QUE for work is placed via nfs into the node specific folder /HIVE/node/$host/que/que-file
que_r() reads the directory, skips . & .. then returns the next value as the que-file
que_up() reads the que-file into an array then deletes it
Life must have a stable state due to its unpredictable nature
que_flush() is the mechanism to ensure that a state is kept by TODO que-file that cycles
api_verify() checks the que-file is digestible for the HIVE environment
All que-file that fail the check will become zombies and must be beheaded (head -n 1) & replanted
|
|
|
|
|
|
####################################################
# 3 - KERN
####################################################
FreeBSD 10.3 kernel is hardened & customized to provide a homogeneous network-environment
The power of unix is its ability to clone increases the network cohesiveness with the intricateness of the clone

  [z] - program install
  [z] - configuration
  [z] - users & groups (section 4)

The system is off-line installation till PSKOPIE
USB is loaded with pre-worked tarballs of sourcecode

Configuration purify the integrity of the unix-hull
Users & groups form the columns that keep structure

# PROGRAMS #########################################

To load the USB with programs to be made available by default
  (1) go to the /usr/ports/ program directory
  (2) make fetch
  (3) sanitize configure file
  (4) if test then tar to USB
  (5) insert program into USB install code

# CONFIGURATION ####################################

sysctl.conf
  [p] - Restrict owner-only process view
  [p] - Restrict member-only group view

  [p] - Tighten

rc.conf
  [p] - host

pf.conf
  All network pipes are structured thru this configuration
  Tables allow for each node to be synced to the other with approved lists
  All tcp communications are hardened with reassemble scrubs
  Traffic is blocked-silent unless there is explicit approval
  Proxy tunnels are established thru net-lists
    [q] source_interface
    [q] destination_addr
    [q] port
    [q] usr


sshd_config
other { ttys, jail.conf, login.conf, ntpd.conf, start_if.}

# ZFS-HEIRARCHY #############################################
/usr/home/
/usr/nfs/pub/
/usr/bin/ - norm bin
/bin - lord bin



# BIN ##############################################

System-executables

The only user that can read a user home directory is root or su-capable user
Privacy of user files is a founding principal of this network
  [#] home
  [#] mail
  [#]
|
|
|
|
|2
|
|
####################################################
# 4 - PSKOPIE
####################################################
Pre-Shared-Key Once-Password-In-Everything
Group RING key types

Each login will require a reduction of the usr usb-bank

# Escalation ######################################
GROUPS
  lord:wheel - su-root
    mreki:lord - su-lord
    betty:lord - su-lord
  heir-lord - su-lord
    hermi:betty - su-betty
    genri:merki - su-mreki

  seer-seer - null
  norm-norm - null

'su' can only be used for ascension
Seer & norm users have no power to 'su'

NODE-tree are exact net-clones
norm1@44m (->) norm1@w2w
norm1@44m (X) norm2@w2w   (FAIL never had norm2-PSK)

USR & GRP are mirrored over hosts
This allows for the seasoned usr to ascend deeper with ease on any host

Remote root is allowed but thru obfuscated-means & alarms
The common-action is to use a hidden & extremely limited accounts

ALICE ASCENSION
 [[3]]
(alice)#
    lord:wheel
------------------                         [[2]]
||               ||      {{  sir:lord  }} (alice)            [[1]]
||               ||                           [y_heir:sir]  (alice)[x_heir:sir]
||               ||                           [y_heir:sir]         [x_heir:sir]
||               ||      {{ mam:lord   }}
||               ||                           [f_heir:mam] [b_heir:mam]
||               ||                           [b_heir:mam] [b_heir:mam]
------------------

# KEY-UPDATE ######################################

/usr/home/usr/.ssh/id_rsa

# KEY$ ############################################

First, to communicate with the network the PSKOPIE KEY$ must be obtained
Kernels exchange files & services for KEY$ that are a fluid source with a finite-lifespan

Elliptic-curves are used in a random array which each kernel mines periodically
KEY$ are then exchanged for increased file-sha on their list

Registers account each transaction of a node,  a unique file can only be on one register, each section of the file a sha-confirmed states
  (1) REGSTR( past + add -  ded )
  (2) {jan-mar} = $sha
  (3) "ALARM" unless (cat REGSTR | grep [jan|feb|mar] | SHA == '$sha')

A usr puts in a QUE-bid for a DEMON which relies on host-load to process
If the output is acceptable output the usr is rewarded with credits it buys connections with

Available kernel KEY$ on a host
{ host } { host } { host }
| KEY$ | | KEY$ | |      |
|_...__| |_...__| |______| . . .

# MARKET ##########################################

KEY$ are exchanged p2p
  [B] SELL - sell uniq data to kern in exchange for token
  [B] XFR - transfer KEY$ for KEY$


KEY$ are managed like stock
The more valuable the host access the more valuable the KEY$

(1)
//zr9\\ ---- $sha_of_unique + zr9_KEY$ ----> //8n8\\
(2)
//8n8\\ ---- $sha_of_unique + zr9_KEY$ ----> //55q\\

1
uniq file archive sha

1000
ftp

100000
krip

1000000
http

1000000000
log

Access to a host if dervived from the network can only happen from lengthy & positive actions

KEY$ are updated on witness of three others
Five sha are confirmed the same & published in a broadcast update

All nodes write broadcast to log
Conflicts will be dealt with noticeably

KEY$ that are inconsistent lock that equal amount in auto-buy
This allows for the system to be adaptable to mistakes in code

This is a system of key wealthy nodes
To prosper all one has to do is improve services

NODE make massive-key trades after a value of NODE
The least inconsistent-locks the more value the KEY$

Incentive to pay for trustworthy-nodes to increase value of TXN

tip witness KEY$

6u8 => 1T KEY$ => 7tw
  Witnesses
    mk1 88r q8l
  XFR worth triples to 3T

This helps centralize efficency the system
But does not detir decentralized transactions

The host modifier is variant in grade of positive bonus onto the TXN
The acient houses empower themselves with longstanding service

|
|
|
|
|
|
|
####################################################
# 5 - PF
####################################################

# RAW ##############################################
Packet Filter is a raw-packet piping
Raw-packet pipe systems allows for the simplest form of action

tcpdump analysis & parsed-output is PSKOPIE posted over the network
[ pflog is read via tcpdump ]

# XCOM #############################################
eXplicit COMmunications kept the hull of the network tight
A solid object is formed as expertise grows

No packet is passed unless it is explicitly-allowed to an explicit-host that is SSL verified
Anti-Middleman techniques used at the network & kernel level

All TCP transactions are scrubbed & reassembled
The subnet behind the NODE is disguised as the node
MAC-addresses are all masked on the network

# TABLES ############################################
Tables are files the system uses to lookup hosts to pass
SSL sockets confirm the identity of the host

(CAPTN_CONFIG discussed later)
Privileged nologin accounts sha-confirm then load the addresses
Approved-list -> sha256 -> post to network -> network confirm -> load list
If the sha does not match the network the table is not loaded

# USR ##############################################
pf allows for a network to pipe data by usr accounts
All accounts are preset & preshared to keep the network clean, simple & stable

|
|
|
|
|
|
|
####################################################
# 6 - SERVICE
####################################################

Every day a node is awarded a token that can be exchanged with a host for KEY$
This incentive will increase a network wide service branch

DNS
NTP
SSH
MAIL
FTP
NFS
HTTP
SCP-WALKITALKI
MORSE
|
|
|
|
|
|
|
####################################################
# 7 - ZFS & Hardware
####################################################


|
|
|
|
|
|
|
####################################################
# 8 - Schematics
####################################################
|
|
|
|
|
|
|
####################################################
# 9 - STAT
####################################################
|
|
|
|
|
|
|

4####################################################
# MKRX UNIX NETWORK

                                             ~ skrp
                                       Kehkay Genkai
                                      of the village
                                  Hidden in the 1337
{{  t_(o0)_j  }}
\\ Meri Kann //
_\\cibR punX//______________________________________
|
|
|
|
|
|
|
This manuscript details the machine of MKRX UNIX NETWORKS
This system connects nodes thru encrypted tunnels

Network Value is contained in 4 sectors
  {#} Storage shares - nfs
  {#} Process clones - HIVE
  {#} Cryptographic Security - PSKOPIE elliptic-curves
  {#} Services - ssh

The following code is the logical infrastructure of the network :

https://github.com/skrp/SICC
SICC network file system

https://github.com/skrp/MKRX
MKRX archive tools

https://github.com/skrp/HIVE
https://github.com/skrp/MINT
HIVE work processors & interface

https://github.com/skrp/ECHO
KERN hardened FreeBSD_10.3 custom unix kernels
PSK-OPIE privilege partition & escalation
PROTO unix network protocol implementations

ZFS diagrams PCI, SATA, SAS, USB
Schematics & Utilities


Packet Filter (pf) raw packet piping

https://github.com/skrp/DTRACE
STAT node & network dtrace sensor analysis

MAN manuals of instructions & examples
|
|
|
|
|
|
|
Let us preserve all insight
Till the last man walk

That he might not walk
In the darkness of past

Independent of time
Independent of wealth
Independent of government

In the order of Anarchy
In that way deliver basic rights

Files get lost
Storage gets easier
|
|
|
|
|
|
|
####################################################
# Table of Contents
####################################################

# 0 ################################################
SICC
  Standard
  Metadata
  Key
  shaper
  BLKR

# 1 ################################################
MKRX
  Tools explained
  Tool use & examples
    create GET from BKUP
    create GET from UNIQ
    populate a new drive
    extract a source

# 2 ################################################
HIVE
  Structure
  Mechanics
    ORDER
    SLEEP
    SUICIDE
    CLEAN
    RESUME
  API
    SHA
    GET
    UNTAR
    REGX
    BLKR
  Logs

# 3 ################################################
KERN
  Hardened
  PSK-OPIE
  RINGS (rings of power)
  USR
    root
    sroot
    lord
    heir
    seer
    norm

# 4 ################################################
PSK-OPIE
  Review
  ASIGN
  Mine
    KEY
    RAW

# 5 ################################################
PROTO
  Overview
  SSH
  SCP
  FTP
  PF
  NFS
  IRC
  8080
  HTTPS
  MORSE

# 6 ################################################
STAT
  List
  dtrace
    cpu
    PID
    fs
    net
  Performance
    LOG
    ECHO
  ANAL
    SELF
    NET

# 7 ################################################
ZFS & Hardware
  ZFS
    0
    Mirror
    raidz2
    raidz3
  Hardware
    BOX
    BIOS
    cpu
    RAM
    PCI
    DEV
    Supply
    PCI
    SATA
    SAS
    USB
    JBOD

# 8 ################################################
SCHMATIC
  SIMP
  TOWR
  Utilities

# 9 ################################################
MAN
  unix manuals
    log
    mount
    boot
    ntfs
  perl manuals
    log
    language
    modules
  zfs manuals
    log
    hotswap
    import
    set
  dtrace manuals
    language

# END ##############################################
|
|
|
|
|
|
|
####################################################
# 0 - SICC
####################################################

######## System In Complete Chaos    ###############

Storage shares are the most important factor in this network
Archive-oriented structures are implemented as a network-wide pursuit of unique files

/usr/nfs/dump/ 330 write-only dump-dir which will be scraped into the SICC-system at /usr/nfs/pub/
(this exposes the pub to the network for file exchange)
SICC will process all files into a sane manner built to handle massive numbers

Storage has a next important factor is entropy strength
Entropy is stored to be traded with other hosts

Entropy over-time multiple-source random-selection
Each Private-Key stored as its sha

To sum up
Data is kept as a sea such that the listing freeze a system

Obfuscation by explicit filename requests
Random-parts of random-files in hexadecimal order with no association

To piece together the file
  [:D] - Metadata file
  [:D] - KEY file
  [:D] - shape pool
  [:D] - KEY$ payment

# NAME SYSTEM ######################################

The core of this system is based on sha file computation

Sha is a unique file identifier that is the output of a mathematical algorithm
This mathematical algorithm will produce the same sha for the same file

Each file is named after its sha

This name system has two benefits:
  {1} de-duplicates files
  {2} assigns data into chaotic order

Sha uniqueness keeps all data:
  [-] simple
  [-] homogeneous
  [-] ultra-transient

The duplication of data is accounted in lists
Each data-pool is maximized in its ability to minimize the data-pool's disk-footprint

The duplication count allows for network backup prioritization to remote devices
This foundation is stable for automated backup management of massive-distributed-data

# METADATA #######################################

Metadata is kept isolated from data
This isolation allows for the obfuscation of open data

Data-pool lists have lessened-value without Metadata
Exposure of lists can be nullified by salt

Only someone that has the metadata & access-key can request data

This file-system is built for ultra-transient network management
All files are located in the directory "/usr/nfs/pub/"

Two factors assist in obfuscation
  (1) No subdirectories to betray association
  (2) Alpha-numeric ordering of the hexadecimal names

The path allows for past-association to be deduced for group-reconstruction
Each file is periodically verified to have a corresponding metadata-file

Each metadata-file consists of 4 lines:
  (1) name - XS (MKRX) standardized name
  (2) path - XS standardized path of extraction
  (3) size - number of bytes
  (4) encode - type of encoding

# KEY ##############################################

A KEY is a recipe to rebuild an obfuscated file

This allows for a powerful layer of unprecedented obfuscation
What is public gibberish is made private information thru access to a KEY file

Each KEY file is named after the original file sha
The KEY file contains sequential sha-per-line lists

Obfuscation Methods:

  [X] shaper (secure against file-known)
        Shreds a file into random-sized parts & creates KEY
        Random-size prevents sha rainbow-tables of attacker with file-known

  [X] BLKR (insecure if file-known)
       Shreds file into standard-sized blocks & creates KEY
       Homogeneous data types will have duplicate-collisions which nullify the duplicate data
       Only one copy of data can exist in the data-pool
       Many KEY files can correspond to the same block reducing the data-pool disk-footprint
       The smaller block-size the greater power of compression & obfuscation of data-pool
       Each node configures own block-size

# SUMMARY #########################################

This file-system spread over a network has the following benefits:
  [o] All data easily accounted for in simple lists
  [o] Sane & clean orders of massive-data on an network
  [o] Network level explicit control of the duplication of data
  [o] Each node serves what is possible
  [o] Each node has access to total data
  [o] Each node can assist in external backups
  [o] Total network-pool footprint is minimized

On a homogeneous unix kernel the network file-system is transparent
Only active tunnels will be displayed as available data-pools

Transparent file-system
  [l] store data remotely
  [l] get a remote file
  [l] serve a local file
  [l] backup network to local drive
|
|
|
|
|
|
|
####################################################
# 1 - MKRX
####################################################
Tools to administer the network file-system

MKRX Tools:
  [XS]
    Extract & Standardize Recursively
  [SCRUB]
    Verify if sha of file is true
  [CHKMETA]
    Confirm each file has metadata
  [UNIQ]
    Output unless (ARG1-files exist in ARG2-files)
  [XFR]
    Serve data to local drive
    Serve data to remote locations
  [INDEX]
    Build Metadata hash-dumps
  [CLI]
    Load INDEX hash-dumps into memory
    Terminal Input & Output produce single-entry lists


# XS ###############################################

Extract & Standardize All Files Recursively
  Send data to pool-dir
  Build metadata in g-dir

This process is the gateway for files to enter the archive
High io usage & multiple process utilization

Features the expert developer kent\n
This code been worked over 100s millions of files

Automatic logic
Just point & pull trigger

Name & path values are standardized to keep environment safe
The path allows for past-association awareness
Size & encoding keep calculations one-time-only

# UNIQ ############################################

Output if ARG1 does-not-exist in ARG2

Filter data that is unique on the network
Compare NODE-list against NET-list
Backup the network with priority files needing duplication

This is a very useful command
It can handle millions of iterations in both ARGs

Learn the simple code mechanic & this command will prove a general system tool
In minutes this processes data that would require many days for grep

# CLI ############################################

Interface to network archive requests custom file requests
This is a daemon server that keeps METAMASTER in memory
Transactions are hexadecimal arrays

  [1] Build INDEX hash-dumps into memory
    This may take several minutes due to massive-data

  [2] Build array-list
    Set to network array-list
    Load a custom array-list from file

  [3] Filter down array list
    Use perl regular-expressions to parse patterns

  [4] Report on array-list
    Print a filtered array to file
    Count the quantity in array-list
    Output the corresponding array-list value
      name, path, size, encode

  [5] Create lists of files bound to a byte-parameter
    The calculation of sums add up when it is to the millions
    Array-list is sectioned into specific-sized chunks

  [6] Use XFR to request the files into home directory
    This process will only require a feed of the output which is the array-list
    Array-list will always only be the sha of filtered file-metadata

  [7] Use conditional regular-expressions to edit the array-list names into a new-file
    After XFR complete use new-file to rename array-list files

Command Menu:
  {regx}  regx data filters
  {reset} reset array to full network-array
  {load}  load array from custom file
  {print} output current array to file
  {count} count array
  {value} output values of array 'name, path, size, encoding'
  {pop}   output size-specific lists that sum to a specific-amount of bytes
  {name}  edit name using conditional regx into new-file

# EXAMPLES #######################################

[1]
Create GET for backup
  {TOTAL_NET}   location of network-wide file list
  {TOTAL_LOCAL} location of local file list
  {GET}         single-entry line lists of what TOTAL_LOCAL lacks from TOTAL_NET
+++++++++++++++++++++++++++++++++++++++++++++++++++
$usr@host> UNIQ TOTAL_NET TOTAL_LOCAL GET
+++++++++++++++++++++++++++++++++++++++++++++++++++

[2]
Create EXTRACT from UNIQ
  {TOTAL_SOURCE} sha lists of a source
  {TOTAL_NET} network-wide file list
  {EXTRACT} new unique files to network list
+++++++++++++++++++++++++++++++++++++++++++++++++++
$usr@host> UNIQ TOTAL_SOURCE TOTAL_NET EXTRACT
+++++++++++++++++++++++++++++++++++++++++++++++++++

[3]
Populate a new drive
  {~/INDEX/}         location of INDEX metadata database hash dumps
  {~/POP/1000000000} file to transfer
  {/mnt/USB/pool/}   location to dump files
+++++++++++++++++++++++++++++++++++++++++++++++++++
$usr@host> CLI ~/INDEX/
pop 1000000000
exit
+++++++++++++++++++++++++++++++++++++++++++++++++++
$usr@host> cd ~/POP/
+++++++++++++++++++++++++++++++++++++++++++++++++++
$usr@host> wc -l 1000000000
8493719 1000000000
+++++++++++++++++++++++++++++++++++++++++++++++++++
$usr@host> wc -l leftover_1000000000
39533365846 leftover_1000000000
+++++++++++++++++++++++++++++++++++++++++++++++++++
$usr@host> XFR ~/POP/1000000000 /mnt/USB/pool/
+++++++++++++++++++++++++++++++++++++++++++++++++++
$usr@host> CLI ~/INDEX/
load leftover_1000000000
pop 1000000000
exit
+++++++++++++++++++++++++++++++++++++++++++++++++++
Loop over & over by gigabyte-sized fragments

[4]
Extract a source
  {/mnt/bkup10/} location to grab new data
  {~/} location to dump data into ~/pool/ & ~/g/
+++++++++++++++++++++++++++++++++++++++++++++++++++
$usr@host> XS /mnt/bkup10/ ~/
+++++++++++++++++++++++++++++++++++++++++++++++++++


# DISK #############################################

Two types of storage
  [r] - root storage
    This is a location that resides upon a root-file-system of a kernel
      /usr/nfs/pub/
  [r] - flat storage
    An external disk that contains only an imported pool of files
      /37w/pool/ or /usr/nfs/37w/pool/

/usr/nfs/pub/  - zfs mount
/usr/nfs/373/  - nfs mount
/usr/nfs/y7u/  - nfs mount

External-drives are necessary for clean access to a file-system
A foreign system can port-itself to mount the simple zfs file-system

The root storage is only slightly more complex
A trade to only then need a amd64 machine architecture to start up


/zroot/boot/ - lord only privilege
---------------------------- DESCRETE LINE
/usr/nfs/pub/ - zfs quota protection
/usr/nfs/el1/ - nfs mount
/usr/nfs/z87/ - nfs mount
|
|
|
|
|
|
|
####################################################
# 2 - HIVE
####################################################

Network TXN (transactions) are based on KEY$ currency
Creating & trading private-keys as a means for network access

Usr sends unstable-input to HIVE
A DEMON stablizes-input & computes
HIVE deposits payment into usr bank
Usr buys host-keys & trades them for specified-host-keys

Each heart of each node singular in the aim of Archive
Data stored for the future & it will offer refuge to any helpful

Encode bounty * group-multiplier = payment
Payment is exchanged for group-limited private-keys

Private-key will be used to open a tunnel
Pre-Shared-Key One-Time-In-Everything
_

Massive projects will be broken down into iterative-tasks
Usr will work DEMON upon sections of those iterative-tasks

Two quest areas
  ["] - harvest of novel workloads lists
  ["] - compute lists

Each project will be distributed to array-computation

project / network-nodes = time
  time + network latency = total-time

Benefits of network-sync-computation
  Randomize Entropy Sources
  Scrape data off from many sources to not cause attention
  Shred data into random-sized blocks
  Clean up host into network dump
  Allow many users to contribute metadata to Archive Collections Interface
  Distribute loads from disk to network to cpu to disk... to empower robustness
  Health-Beat of host via dtrace anchors

A network of DEMON (unix daemon) work on a schedule
  Busy (low all)
    Scrape http data
  Mid (low net)
    Entropy collection
  Bored (high all)
    shaper
    SHA

# NET ##############################################

HIVE
    {T}    get www.pedrk.com/tome.txt
  {     }  blkr $i
{ FACE    }
    ||
    ||
    ||
    ||
    ||                    key_4ff38 < [usr]
    ||                    key_ff9aae   v   > key_d3413
    ||
    ||
    ||
   {T}       sleep 3600                                {T}      sleep 3600
 {     }     get www.nasa.com/sun/index.html         {     }    kripkey
{ FACE  } ========================================{ FACE     }  shaper $i

FACE
This is an ASCII graphical representation of the NODE
STATE represents the HOST each report independent to other DEMON
  [y] NAME
  [Y] STATE
  [y] AGE_IN_HOURS
  [y] SUCCESSFUL_ITERATIONS (YAY, 5-line-success-buffer)


Commands (all or node)
  PING - alive last 15-min
  SLEEP - pause all (may take forever to infinity)
  RAW - all output log
  HICC - fail / error
  BURP - cat log of successful iterations
  FACE - echo DEMON portrait
  REIN - iograph of net & individual data
  BARK - { [PING * ALLOWANCE] < 10%_expected }
  SUICIDE - clean-up then kill-itself

A HIVE cumulative workload should never breach 20% of maximum
The goal behind this work is to allow sanity thru dissociative-scheduled-massive-computation of a network of these HIVE

# NODE #############################################

A unix daemon is an process that severs all-but-explicit interface file descriptors
This provides an independence which stabilizes the foundation of the code
This code is a summon-scroll crafted to deal with specific actions
  The process can be suspended-shutdown-update_que by an admin able to write in a locked-down dir
  The DEMON-INTERFACE will all specific tasks in an explicit command execution

The Achilles heel of distributive computing are fork-bombs & defunct-muthrfkrs
Fork bombs are nasty & bloom out of any inconsistency [like invasive network probes]
Defunct processors are unkillable in certain situations
You can never automate continuously running programs without a sensitivity to host health
There is a reason animals have a nervous system & we must forward those lessons onto the machine race
The sensitivity of the host system will be the stable foundation with catches fork bombs
  Every host will have an avatar maintained by HIVE
  This will be a depiction of the health which will have numerical value
  If any net-process over 50% utilized-cpu then cleanup & exit or sleep

Full-access given to any network node with proper Pre-Shared-Keys Once-In-Everything-Passwords
This allows a network to be delegated remotely to partitioned unix groups
  pig_fkn_redneck wants a torrent downloaded at maximum-strength crypto
  The code will inspect the PSK, shift the key off the array, and have x proxy nodes download the file in pieces
  When the torrent is complete, verified & archived it is placed in /usr/home/pig_fkn_redneck/torrent/Udders_for.udder.lovers.mp4

# FUNCTIONS #########################################

tombstone() name() time()
Each DEMON has a unique name that will be memorialized with its lifeswork
For a member to enrich the whole, first the society must cherish the member
The tombstone is a snapshot of the last DEMON portrait FACE

que_r() que_up() que_flush() api_verify()
QUE for work is placed via nfs into the node specific folder /HIVE/node/$host/que/que-file
que_r() reads the directory, skips . & .. then returns the next value as the que-file
que_up() reads the que-file into an array then deletes it
Life must have a stable state due to its unpredictable nature
que_flush() is the mechanism to ensure that a state is kept by TODO que-file that cycles
api_verify() checks the que-file is digestible for the HIVE environment
All que-file that fail the check will become zombies and must be beheaded (head -n 1) & replanted
|
|
|
|
|
|
####################################################
# 3 - KERN
####################################################
FreeBSD 10.3 kernel is hardened & customized to provide a homogeneous network-environment
The power of unix is its ability to clone increases the network cohesiveness with the intricateness of the clone

  [z] - program install
  [z] - configuration
  [z] - users & groups (section 4)

The system is off-line installation till PSKOPIE
USB is loaded with pre-worked tarballs of sourcecode

Configuration purify the integrity of the unix-hull
Users & groups form the columns that keep structure

# PROGRAMS #########################################

Pre-load the USB with programs to be made available by default
  (1) go to the /usr/ports/ program directory
  (2) make fetch
  (3) sanitize configure file
  (5) insert program into USB install code
  (4) if test then tar to USB

perl-modules
  LWP::Protocol::https

unix-packages
  perl5
  bash

# CONFIGURATION ####################################

sysctl.conf
  [p] - Restrict owner-only process view
  [p] - Restrict member-only group view
  [p] - Tighten network settings

rc.conf
  [p] - Dynamic Host Control Protocol (DHCP)
  [p] - Gateway will determine address & uses that as subnet external-interface
  [p] - Hostname is a uniq 3 character identifier
  [p] - Kernel modules loaded
  [p] - Services are started
  [p] - System options set

pf.conf
  All network pipes are structured thru this configuration
  Tables allow for each node to be synced to the other with approved lists
  All tcp communications are hardened with reassemble scrubs
  Traffic is blocked-silent unless there is explicit approval
  Proxy tunnels are established thru net-lists
    [q] source_interface
    [q] destination_addr
    [q] port
    [q] usr

start_if.
  This will mask the MAC for network communications
  This mask is imperative to network security

ttys && login.conf
  Remove direct root access
  Require root-password to single-user-mode

ntpd.conf
  OpendBSD built ntp server to sync all nodes
  There is no external-ntp-server
  All NODE sync to the other

sshd_config
  PermitRootLogin no
  PasswordAuthentication no
  UsePAM no
  AllowGroups ssh
  Protocol 2
  MaxAuthTries 4
  RSAAuthentication yes
  PubkeyAuthetication yes
  AuthorizedKeysFile .ssh/authorized_keys
  ChallengeResponseAuthentication yes

# ZFS-HEIRARCHY #############################################
/usr/home/
/usr/nfs/pub/
/usr/bin/ - norm bin
/bin - lord bin



# BIN ##############################################

System-executables

The only user that can read a user home directory is root or su-capable user
Privacy of user files is a founding principal of this network
  [#] home
  [#] mail
  [#]

|
|
|
|
|
|
|
####################################################
# 4 - PSKOPIE
####################################################
Pre-Shared-Key Once-Password-In-Everything
Group RING key types

Each login will require a reduction of the usr usb-bank

# Escalation ######################################
GROUPS
  lord:wheel - su-root
    mreki:lord - su-lord
    betty:lord - su-lord
  heir-lord - su-lord
    hermi:betty - su-betty
    genri:merki - su-mreki

  seer-seer - null
  norm-norm - null

'su' can only be used for ascension
Seer & norm users have no power to 'su'

NODE-tree are exact net-clones
norm1@44m (->) norm1@w2w
norm1@44m (X) norm2@w2w   (FAIL never had norm2-PSK)

USR & GRP are mirrored over hosts
This allows for the seasoned usr to ascend deeper with ease on any host

Remote root is allowed but thru obfuscated-means & alarms
The common-action is to use a hidden & extremely limited accounts

ALICE ASCENSION
 [[3]]
(alice)#
    lord:wheel
------------------                         [[2]]
||               ||      {{  sir:lord  }} (alice)            [[1]]
||               ||                           [b_heir:sir]  (alice)[x_heir:sir]
||               ||                           [w_heir:sir]         [n_heir:sir]
||               ||      {{ mam:lord   }}
||               ||                           [f_heir:mam] [n_heir:mam]
||               ||                           [a_heir:mam] [z_heir:mam]
------------------

# KEY-UPDATE ######################################

/usr/home/usr/.ssh/id_rsa
/usr/home/usr/.ssh/id_rsa.pub

Usr accounts have a finite lifespan
Time added at cost that is reduced upon time-in-relation of the host-system

# KEY$ ############################################

First, to communicate with the network the PSKOPIE KEY$ must be obtained
Kernels exchange files & services for KEY$ that are a fluid source with a finite-lifespan

Elliptic-curves are used in a random array which each kernel mines periodically
KEY$ are then exchanged for increased file-sha on their list

Registers account each transaction of a node,  a unique file can only be on one register, each section of the file a sha-confirmed states
  (1) REGSTR( past + add -  ded )
  (2) {jan-mar} = $sha
  (3) "ALARM" unless (cat REGSTR | grep [jan|feb|mar] | SHA == '$sha')

A usr puts in a QUE-bid for a DEMON which relies on host-load to process
If the output is acceptable output the usr is rewarded with credits it buys connections with

Available kernel KEY$ on a host
{ host } { host } { host }
| KEY$ | | KEY$ | |      |
|_...__| |_...__| |______| . . .

# MARKET ##########################################

KEY$ are exchanged p2p
  [B] SELL - sell uniq data to kern in exchange for token
  [B] XFR - transfer KEY$ for KEY$


KEY$ are managed like stock
The more valuable the host access the more valuable the KEY$

(1)
//zr9\\ ---- $sha_of_unique + zr9_KEY$ ----> //8n8\\
(2)
//8n8\\ ---- $sha_of_unique + zr9_KEY$ ----> //55q\\

1
uniq file archive sha

1000
ftp

100000
krip

1000000
http

1000000000
log

Access to a host if dervived from the network can only happen from lengthy & positive actions

KEY$ are updated on witness of three others
Five sha are confirmed the same & published in a broadcast update

All nodes write broadcast to log
Conflicts will be dealt with noticeably

KEY$ that are inconsistent lock that equal amount in auto-buy
This allows for the system to be adaptable to mistakes in code

This is a system of key wealthy nodes
To prosper all one has to do is improve services

NODE make massive-key trades after a value of NODE
The least inconsistent-locks the more value the KEY$

Incentive to pay for trustworthy-nodes to increase value of TXN

tip witness KEY$

6u8 => 1T KEY$ => 7tw
  Witnesses
    mk1 88r q8l
  XFR worth triples to 3T

This helps centralize efficency the system
But does not detir decentralized transactions

The host modifier is variant in grade of positive bonus onto the TXN
The acient houses empower themselves with longstanding service


norm has to que
lord has no que

NODE has 10000 stock
As the NODE increases in value to the network each stock increases

SPLIT: when a node doubles in value

1000000 is actually 10000 invested ports

Portal out of limbo
  [u] USR -> PSKOPIE -> port
  [u] port -> PSKOPIE -> usr

A port account is a sleep'n gate keeper
It is only woken when asked-for

This allows for several thousand direct-portals open
Yet at the same time requires null resource

USR holds stock xf71038 a year
After USR gets access into the port
port PSKOPIE use
The USR su 'boobnorm'
norm PSKOPIE use
cd ~/

0i3 -> PSKOPIE_SET accounts -> SELL pool
48o -> BUY 0001norm@0i3 stock -> CLAN bank

0i3 Host nfs 6mo & doubles in timeout-length
48o CLAN bank -> 0001norm@0i3 -> double length logins

It takes 1 month of positive activity
To become worth the exchange to a single stock

File worth:
  [c] prime
  [c] second
  [c] third
  [c] fourth - unverified file

This is the incentive to hold a unique file of value
To own that prime & hold it or sell it hot

Local storage or net-trade
bob_3y89d rents space for prime file storage
  + net salary
  + usr rent income

Use of remote nodes is useful & encouraged
Nodes offer transient storage for the BLK_CLD of files
|
|
|
|
|
|
|
####################################################
# 5 - PF
####################################################

# RAW ##############################################

Packet Filter is a raw-packet piping
Raw-packet pipe systems allows for the simplest form of action

tcpdump analysis & parsed-output is PSKOPIE posted over the network
[ pflog is read via tcpdump ]

# XCOM #############################################

eXplicit COMmunications kept the hull of the network tight
A solid object is formed as expertise grows

No packet is passed unless it is explicitly-allowed to an explicit-host that is SSL verified
Anti-Middleman techniques used at the network & kernel level

All TCP transactions are scrubbed & reassembled
The subnet behind the NODE is disguised as the node
MAC-addresses are all masked on the network

# TABLES ############################################

Tables are files the system uses to lookup hosts to pass
SSL sockets confirm the identity of the host

(CAPTN_CONFIG discussed later)
Privileged nologin accounts sha-confirm then load the addresses
Approved-list -> sha256 -> post to network -> network confirm -> load list
If the sha does not match the network the table is not loaded

All usrs approved on the network share the same tables
Every usr knows the identity of all other users securely

The configuration memory is sha-verified to confirm identity
Each new connection must have a pre-shared-table & PSKOPIE

# USR ##############################################

pf allows for a network to pipe data by usr accounts
All accounts are preset & pre-shared to keep the network clean, simple & stable

|
|
|
|
|
|
|
####################################################
# 6 - SERVICE
####################################################

Every day a node is awarded a token that can be exchanged with a host for KEY$
This incentive will increase a network wide service branch

SSH
  Keep It Simple & Stoopid
  One tunnel in everything
    [h] Shell
    [h] Copy
    [h] Log

    [h] Sockets
        Every connection made thru PSKOPIE

PROXY
  [0]  1337 link
  [1]  one-time-only
  [10] 1337 link
  [1G] prime-time
  [1B] basic-cable

DNS
  Network is predefined only
  Outer-network is define-able

MAIL
  Outer-network proxy sockets
  (SCP) Local only scp message

HTTP
  Proxy on port 8080
  Sockets is a market, the more valuable socket => the more valuable node

NTP
  Sync time is necessary for a network to have cohesion
  OpenNTP is necessary for stability in its security

FTP

NFS
  zfs create usr/nfs
  zfs create usr/nfs/pub
  zfs set sharenfs=on /usr/nfs/pub

  /etc/exports

  rpcinfo
  tcpdump


HTTP
SCP-WALKITALKI
MORSE
|
|
|
|
|
|
|
####################################################
# 7 - ZFS & Hardware
####################################################

# FUNCTIONS ########################################

zpool create $dev addr
++++++++++++++++++++++++++++++++++++++++++++++++++++
+ zpool create usb /dev/da1
+ cd /usb/
++++++++++++++++++++++++++++++++++++++++++++++++++++

zpool create mirror
  [m] mirrors doubles the speed of a filesystem
++++++++++++++++++++++++++++++++++++++++++++++++++++
+ zpool create mirror zroot /dev/da0 /dev/da2
++++++++++++++++++++++++++++++++++++++++++++++++++++

zpool import -f
++++++++++++++++++++++++++++++++++++++++++++++++++++
+ zpool inport -f usb
+ cd /usb/
++++++++++++++++++++++++++++++++++++++++++++++++++++
  [m] DANGER may create unkillable zombie
  [m] usb or sata attached device

zpool export
  [m] DANGER may create unkillable zombie
++++++++++++++++++++++++++++++++++++++++++++++++++++
+ cd ~/
+ zpool export -f usb
++++++++++++++++++++++++++++++++++++++++++++++++++++

zfs snapshot pool@date
++++++++++++++++++++++++++++++++++++++++++++++++++++
+ zfs snapshot usb@10mar17
++++++++++++++++++++++++++++++++++++++++++++++++++++

zfs create -o compression=on $pool
zfs create -o mountpoint='' $pool
zfs set -o sharenfs=on $pool

# SECURITY #########################################

read-only
nfs-share
nfs-MAC

# QUOTA ############################################

This allows for secure partition of files to order
Stability is ensured by zfs file-system caps of data

# zdb ##############################################

 [-] v ...
   mo verbosity da mo bettah

 [-] b
   Block details
 [-] d ...
   Dataset details
   mo d da mo bettah
 [-] m .. mmm
   Metaslab details
   mmm is every spacemap record

 [-] s
   I/O statistics
 [-] h
   History of the pool

 [-] -R $pool vdev:offset:size[:flags]
   manual file read

 [-] u
   get uberblock
 [-] l
   get vdev labels

 [-] A .. AAA
   recover tool
 [-] F
   recover tool

# log ##############################################

zfs list
zpool list
zpool status -x
zfs snapshot pool@date

# admin ############################################

These ZFS issues will breed zombies:
  [k] `zpool import`
  [k] `zpool export`
  [k] io-errors unkempt-disk

Only in prudence attach a pool to a kernel
The zombie lasts until death of the kernel

unix is built to run forever
Respect the ecosystem & it will reward you


|
|
|
|
|
|
|
####################################################
# 8 - Schematics
####################################################
# BIOS #############################################

BIOS is like loving a women
You have to go thru the labor of investigation

  [i] BIOS button [f2] || [f12] || ...
    This button will drop the system into BIOS as a hotkey
  [i] Boot
    Find the drives
    Select the boot drive
    Activation of SATA ports is required on some BIOS
    To learn your machine you must roam the BIOS
  [i] SATA
    The motherboard sata-port position may affect the boot of certain motherboards, try each motherboard SATA port if troubleshooting

# CPU ##############################################

High-power-cores for beefy processing
Multi-quick-cores for mass of calculations

Unix & MKRX keep the system simple
Low-power massive-pool are favored over next-lvl-computation

Bottom-line is if you know why you like your CPU
That is all the only standard which you need
To have that boost-output respective to system-specs

# RAM ##############################################

ECC ram is the best ram because why not
ZFS does not require this ram but it adds a layer of verification

RAM is the perfect mate for ZFS
The better the admin the more need for RAM

MKRX systems is very RAM heavy
Plus cpu time in most of its computation

SPEED HIERARCHY
cpu-cache -> ram -> pci-ssd -> sata-ssd -> sata-hdd -> usb -> net

# BOX ##############################################

Hold 1 / 2 drives
1 SSD
  Quick root filesystem & network access
1 HDD
  Slow but beefy storage

There are several forms of DISK CONNECTION
Use these options to maximize a NODE build

Each motherboard has its ways
To the hacker it may give you headaches
To the scrub it will make you give-up

BIOS specific experience best learned-once
Lessen the diversity of motherboards in a same-admin-network


# DISK CONNECTION  #################################

Kernel requirements to use the hard-disk-drives (HDD)
  [a] Power pin secure to the HDD
  [a] SATA cable secure attached to HDD
  [a] Recognizable File System || overwrite

POWER
  HDD are powered by a pin that can be daisy chained as a power source
  HDD do not require much power and this can allow a node to increase in size

SATA-HDD
  All amd64 motherboards contain an L-shaped port
  A male/female cable will connect the drive to the motherboard

PCI-SATA-HDD
  PCI cards can come from 1-4 SATA ports which add onto drives connectable to the motherboard
  PCI-SAS + PCI-SATA + mobo = many ports

PCI-SAS-HDD
  These use break-out cables that split one into four creating 8 SAS connections (SATA)

JBOD
  ZFS needs the drive to be passed raw free from hardware-raid interventions
  Each raid-card has their own BIOS to search for the JBOD option
  Be sure because if you are wrong you are fkd

USB-SATA
  External-drives in an array with external-power-source
  Modularization & beef up  on a low transaction host
  Power-strip + USB ports + shelf

LSI-SAS-9211-8i
  Preferred Host Bus Adapter
  Direct-disk-passthru-no-bullshit
  Never daisy-chain SATA-data cables
  16 is the expected maximum from the 9211
  This leaves mobo & pci-e sata ports available
  If more than one ZFS pool exists on a mobo - mix disk sources
  8-wide-raidz2 => 4 on hba1 4 on hba2
  7-wide-raidz2 => 4 on hba1 4 on hba2

Hardware-raid-card
  Most raid cards have an option JBOD (just-a-bunch-of-disks)
  Read the manual to see if a direct passthru is possible
  zdb report out the disk-ids to verify individual disk identities
  Only if this succeeds (&&)
  Create a ZFS file system

# TOWER ###############################################

`Dark Tower Steel-Maiden`
42u Steel which bends
To the heft of the drives

The vessel which brought
skrp forever to be recalled
In the tomes of 1337-past-lifetimes

Keekay Gennkai
of the villiage
Hidden In the 1337

To him you are hull
To weather the sea

Constant companion
As planet earth has moods

Into melancholy failure
Aun to the face of death
In but a sharp-quick-turn

I pleaded for companion
Universe sent me you
Magical past contemplation

Till your limits I breach
Only at surface-level

Depths of which dark valleys
Can leave one lost for weeks


   [[98888888888888888888]]
   [[ ===== firewall ====]]
   [[ ===================]]oooooo
   [[ == x3e == 7c7 =====]]     \\
   [[ ___________________]]      ===
   [[ ========= UPS =====]]         \\
   [[ ======= switch ====]]          \\0000000000000
   [[ == powerstrip =====]]           /_____________\
   [[ ====== CHEST ======]]           ' ' ' ' ' ' ' '
   [[ ===================]]
   [[ ====== raid1 ======]]  ________=======,=======_________
   [[ ===================]]
   [[ ===== raid2s ======]]
   [[ ===================]]
   [[ ==== raid3 ========]]
   [[ ===================]]
   [[ ===== scraper =====]]
   [[88888888888888888888]]
   @ @                  @ @

# Utilities ##########################################

  HDD External Case
    house HDD apartments 1
  UPS
    give the router immunity to death for x-min
  CHEST
    lock your private possessions
  switch
    unmanaged pass thru 24 ports
  scraper
    dual-processor scrape-only machine

  cords
    (.) SATA-power daisy-chains
    (.) SAS breakout cables
    (.) Multi-size SATA cables
    (.) Ethernet cable (multi-size / flat / outdoor)
    (.) USB=>SATA-data USB=>SATA-power
    (.) HDMI is the best cable for video
    Do not daisy-chain SATA-data cables


# RAID ###############################################

Raid can be a beautiful thing
They are always true muthrfkrs

Hot-swap is the act of precariously recalculating pool-parity onto a new drive when an old drive has failed
First the physical-location must be known a trial of hardship for white-box-hackers

I have created maps
But despite all efforts the drive-failure + physical-location a complete nightmare

If another drive fails the pool is toast
This a cliff I have myself stared down at

The beauty of simplicity should always be carried out before a raid-array attempted
Very easy to setup but when SHTF they are the worst to deal with

raidz3 at 15 drives wide nears the efficiency of a raidz2
I have run one 3 years without a need for hot-swap or error
NFS serving 75%+ data pool
|
|
|
|
|
|
|
####################################################
# 9 - STAT
####################################################

# UNIX-LOG #########################################

   [M] - NET
   [M] - DISK
   [M] - CPU

# ZFS-REPORTS ##########################################

  [M] - NET
  [M] - DISK
  [M] - CPU

# DTRACE-REPORTS ###########################################

  [M] - NET
  [M] - DISK
      [m] write-latency
      [m] read-latency
      [m] create-latency
  [M] - CPU
    [m] count all syscalls by PID
    [m]

DTrace is a powerful bond between the kernel & hacker
Nobullshit-raw-data-sensor-anchors

Track the host by raw syscalls
Parse the anchor output into intelligent reports
|
|
|
|
|
|
|
Code tips
1) fix syntax
2) review structure for mem-leaks
3) step-into-uncomment-code to correct by block of code

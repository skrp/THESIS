####################################################
# MKRX UNIX NETWORK

                                             ~ skrp
                                       Kehkay Genkai
                                      of the village
                                  Hidden in the 1337
{{  t_(o0)_j  }}
\\ Meri Kann //
_\\cibR punX//______________________________________
|
|
|
|
|
|
|
This manuscript details the machine of MKRX UNIX NETWORKS
This system connects nodes thru encrypted tunnels

SICC network file system
MKRX archive tools
HIVE work processors

KERN hardened FreeBSD_10.3 custom unix kernels
PSK-OPIE privilege partition & escalation

PROTO unix network protocol implementations
STAT node & network dtrace sensor analysis

ZFS diagrams PCI, SATA, SAS, USB
Schematics & Utilities

MAN manuals of instructions & examples
|
|
|
|
|
|
|
Let us preserve all insight
Till the last man walk

That he might not walk
In the darkness of past

Independent of time
Independent of wealth
Independent of government

In the order of Anarchy
In that way deliver basic rights

Files get lost
Storage gets easier
|
|
|
|
|
|
|
####################################################
# Table of Contents
####################################################

# 0 ################################################
SICC
  Standard
  Metadata
  Key
  SLICR
  BLKR

# 1 ################################################
MKRX
  Tools explained
  Tool use & examples
    create GET from BKUP
    create GET from UNIQ
    populate a new drive
    extract a source

# 2 ################################################
HIVE
  Structure
  Mechanics
    ORDER
    SLEEP
    SUICIDE
    CLEAN
    RESUME
  API
    SHA
    GET
    UNTAR
    REGX
    BLKR
  Logs

# 3 ################################################
KERN
  Hardened
  PSK-OPIE
  RINGS (rings of power)
  USR
    root
    sroot
    lord
    heir
    seer
    norm

# 4 ################################################
PSK-OPIE
  Review
  ASIGN
  Mine
    KEY
    RAW

# 5 ################################################
PROTO
  Overview
  SSH
  SCP
  FTP
  PF
  NFS
  IRC
  8080
  HTTPS
  MORSE

# 6 ################################################
STAT
  List
  dtrace
    cpu
    PID
    fs
    net
  Performance
    LOG
    ECHO
  ANAL
    SELF
    NET

# 7 ################################################
ZFS & Hardware
  ZFS
    0
    Mirror
    raidz2
    raidz3
  Hardware
    BOX
    BIOS
    cpu
    RAM
    PCI
    DEV
    Supply
    PCI
    SATA
    SAS
    USB
    JBOD

# 8 ################################################
SCHMATIC
  SIMP
  TOWR
  Utilities

# 9 ################################################
MAN
  unix manuals
    log
    mount
    boot
    ntfs
  perl manuals
    log
    language
    modules
  zfs manuals
    log
    hotswap
    import
    set
  dtrace manuals
    language

# END ##############################################
|
|
|
|
|
|
|
####################################################
# 0 - SICC
####################################################

######## System In Complete Chaos    ###############

# NAME SYSTEM ######################################
The core of this system is based on sha file computation

Sha is a unique file identifier that is the output of a mathematical algorithm
This mathematical algorithm will produce the same sha for the same file

Each file is named after its sha

This name system has two benefits:
  {1} de-duplicates files
  {2} assigns data into Chaos order

Sha uniqueness keeps all data:
  [-] simple
  [-] homogeneous
  [-] ultra-transient

The duplication of data is inherently accounted in single-entry lists
Each data-pool is maximized in its ability to minimize the data-pool's disk-footprint
The obvious duplication count allows for network backup prioritization

# METADATA #######################################
Metadata is kept isolated from the data
This isolation allows for the obfuscation of open data

Data-pool lists are useless without Metadata
Files can only be accessed by explicit name transfers
  [+] get $sha
  [+] send $sha

This file-system  is built for ultra-transient network management
All files are located in the directory "/usr/nfs/pub/"

Two factors assist in obfuscation
  (1) No subdirectories to betray association
  (2) Alpha-numeric ordering of the hexidecimal names in single-pool grouping prevent list snooping


Each file is periodically verified to have a corresponding metadata-file
Each metadata-file consists of 4 single-line entries:
  (1) name - XS (MKRX) standardized name
  (2) path - XS standardized path of extraction
  (3) size - number of bytes
  (4) encode - type of encoding

# KEY ##############################################
A KEY is a recipe to rebuild an obfuscated file

This allows for a powerful layer of unprecedented obfuscation
What is public gibberish is made private information thru access to a KEY file

Each KEY file is named after the original file sha
The KEY file contains sequential sha-per-line entries

Obfuscation Methods:

  [X] SLICR (secure against file-known)
        Shreds a file into random-sized parts & creates KEY
        Random-size prevents sha rainbow-tables if the attacker knows file

  [X] BLKR (insecure if file-known)
       Shreds file into standard-sized blocks & creates KEY
       Homogeneous data types will have duplicate-collisions which nullify the duplicate data
       Only one copy of data can exist in the data-pool
       Many KEY files can correspond to the same block reducing the data-pool foot-print
       The smaller block-size the greater power of compression & obfuscation
       Each node configures own block-size

# END ##############################################

This file-system spread over a network has the following benefits:
  [o] All data easily accounted for in single-entry lists
  [o] Sane & Clean orders of massive-data on an network
  [o] Network level explicit control of the duplication of data

On a homogeneous unix kernel the network file-system is transparent
Only active tunnels will be displayed as available data-pools

Transparent file-system
  [l] store data remotely
  [l] get a remote file
  [l] serve a local file
  [l] backup network to drive
|
|
|
|
|
|
|
####################################################
# 1 - MKRX
####################################################

Tool summary

SCRUB
Verify sha of the data is true
Report untrue data

CHKMETA
Confirm each file has metadata
Report rogue data

UNIQ
Check if data is unique to the network
Compare NODE data against NET data
Create add backup duplicates to network

XFR
Get data onto local drive

INDEX
Update metadata database hash dumps

CLI
Load INDEX into memory
Terminal Input & Output to produce single entry lists

API
 RESET - reset array to full network-array
 LOAD - load array from custom file
 PRINT - output current array
 COUNT - count array
 VAL - output values of array 'name, path, size, encoding'
 POP - output size specific lists to fill up the specific amount of bytes

  Use & example
 create GET for backup
$usr@host> UNIQ TOTAL_NET TOTAL_LOCAL GET
TOTAL_NET - location of network-wide file list
TOTAL_LOCAL - location of local file list
GET - will now have line-per-entry list of what TOTAL_LOCAL lacks from TOTAL_NET

 create EXTRACT from UNIQ
$usr@host> UNIQ TOTAL_SOURCE TOTAL_NET EXTRACT
TOTAL_SOURCE - sha lists of a source
TOTAL_NET - network-wide file list
EXTRACT - new files to append to network-wide list

 populate a new drive
$usr@host> CLI ~/INDEX/
~/INDEX/ - location of INDEX metadata database hash dumps

pop 1000000000
exit

$usr@host> cd ~/POP/

$usr@host> wc -l 1000000000
8493719 1000000000

$usr@host> wc -l leftover_1000000000
39533365846 leftover_1000000000

$usr@host> XFR ~/POP/1000000000 /mnt/USB/pool/
~/POP/1000000000 - file to transfer
/mnt/USB/pool/ - location to dump files

$usr@host> CLI ~/INDEX/

load leftover_1000000000

pop 1000000000
exit

 loop over & over by gigabyte sized fragments

 extract a source
$usr@host> XS /mnt/bkup10/ ~/
/mnt/bkup10/ - location to grab new data
~/ - location to dump data into ~/pool/ & ~/g/
|
|
|
|
|
|
|
####################################################
# 2 - HIVE
####################################################

  HIVE
 DEMON - always online unix daemon goons with network API

  NODE Structure
 /tmp/$NAME/dump/ - DEMON specific host dump
 /tmp/PING - host DEMON roster

  NET Structure
 /HIVE/ - nfs remote mount
 /HIVE/PING - net DEMON roster
 /HIVE/node/$NODE - node specific directory
 /HIVE/node/$NODE/PID - node specific PID rooster
 /HIVE/node/$NODE/QUE/ - host specific API que
 /HIVE/cemetery/ - network wide DEMON graveyard
 /HIVE/cemetery/RAW_$NAME -
 /HIVE/cemetery/DONE_$NAME -
 /HIVE/cemetery/TODO_$NAME -

  Dump
 /$nfs_pool/ - remote que file dump
 /$nfs_g/ - remote que meta dump

  Mechanics
 ORDER
 SLEEP
 SUICIDE
 CLEAN
 RESUME

  API
 SHA - sha a file
 GET - http request URL & XS file into remote dump
 UNTAR - extract file archive type & XS into remote dump
 REGX - test massive-data for patterns
 BLKR - shred files into standard-blocks
 SLICR - shred files into random-blocks

  Logs


|
|
|
|
|
|
|
####################################################
# 3 - KERN
####################################################
|
|
|
|
|
|
|
####################################################
# 4 - PSKOPIE
####################################################
|
|
|
|
|
|
|
####################################################
# 5 - PROTO
####################################################
|
|
|
|
|
|
|
####################################################
# 6 - STAT
####################################################
|
|
|
|
|
|
|
####################################################
# 7 - ZFS & Hardware
####################################################
|
|
|
|
|
|
|
####################################################
# 8 - Schematics
####################################################
|
|
|
|
|
|
|
####################################################
# 9 - MAN
####################################################
|
|
|
|
|
|
|
